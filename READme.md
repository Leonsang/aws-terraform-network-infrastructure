# üõ°Ô∏è Proyecto de Detecci√≥n de Fraude Financiero con Terraform

[![AWS](https://img.shields.io/badge/AWS-Powered-orange)](https://aws.amazon.com/)
[![Terraform](https://img.shields.io/badge/Terraform-v1.2.0+-blueviolet)](https://www.terraform.io/)
[![Kaggle](https://img.shields.io/badge/Dataset-Kaggle-blue)](https://www.kaggle.com/c/ieee-fraud-detection)
[![Licencia](https://img.shields.io/badge/Licencia-MIT-green)](LICENSE)

Este proyecto implementa un sistema completo de ingenier√≠a de datos para detecci√≥n de fraude financiero en AWS, utilizando Terraform para la infraestructura como c√≥digo. El sistema est√° dise√±ado siguiendo una arquitectura Lakehouse con tres zonas de datos y componentes para procesamiento por lotes y en tiempo real.

## üìã Tabla de Contenidos

- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Dataset](#-dataset)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Gu√≠a de Instalaci√≥n](#-gu√≠a-de-instalaci√≥n)
- [Componentes Principales](#-componentes-principales)
- [Escalabilidad y Rendimiento](#-escalabilidad-y-rendimiento)
- [Documentaci√≥n Detallada](#-documentaci√≥n-detallada)
- [Licencia](#-licencia)
- [Contacto](#-contacto)

## üèóÔ∏è Arquitectura del Sistema

![Arquitectura del Sistema](docs/diagrams/architecture.png)

El sistema sigue una arquitectura Lakehouse en AWS con tres zonas principales:

### Raw Zone (Bronze) ü•â
- **Prop√≥sito**: Almacenamiento de datos sin procesar
- **Implementaci√≥n**: Bucket S3 con catalogaci√≥n mediante Glue Crawler
- **Formato**: Original (CSV) o Parquet con compresi√≥n
- **Caracter√≠sticas**: Inmutabilidad, retenci√≥n configurable, particionamiento por fecha

### Processed Zone (Silver) ü•à
- **Prop√≥sito**: Datos limpios y transformados
- **Implementaci√≥n**: Bucket S3 con modelo estrella implementado
- **Procesamiento**: ETL gestionado con AWS Glue
- **Caracter√≠sticas**: Validaci√≥n de calidad, normalizaci√≥n, enriquecimiento

### Analytics Zone (Gold) ü•á
- **Prop√≥sito**: Vistas materializadas para an√°lisis
- **Implementaci√≥n**: Bucket S3 + Redshift (en prod)
- **Visualizaci√≥n**: Integraci√≥n con QuickSight
- **Caracter√≠sticas**: Optimizaci√≥n para consultas, agregaciones, m√©tricas

### Flujo de Datos

```
Ingesta ‚Üí Raw Zone ‚Üí Procesamiento ‚Üí Processed Zone ‚Üí An√°lisis ‚Üí Analytics Zone
   ‚Üë                     ‚Üë                                 ‚Üì
Tiempo Real         Batch (Glue)                      Dashboards
(Kinesis)                                            (QuickSight)
```

Para una vista m√°s detallada del flujo de datos, consulta el [diagrama de flujo completo](docs/diagrams/data_flow.png).

## üìä Dataset

El proyecto utiliza el dataset **IEEE-CIS Fraud Detection** disponible en Kaggle, que contiene m√°s de 1 mill√≥n de registros de transacciones financieras con etiquetas de fraude verificadas.

### Caracter√≠sticas del Dataset

- **Tama√±o**: >1 mill√≥n de registros
- **Archivos**:
  - `identity_*.csv`: Informaci√≥n de identidad de los usuarios (~140MB)
  - `transaction_*.csv`: Informaci√≥n de las transacciones financieras (~590MB)
- **Variables**: M√°s de 400 caracter√≠sticas, muchas an√≥nimas por confidencialidad
- **Etiquetas**: Clasificaci√≥n binaria (fraude/no fraude)

### Descarga Autom√°tica

El proyecto incluye un sistema automatizado para descargar el dataset directamente desde Kaggle y cargarlo en el bucket S3 Raw, eliminando la necesidad de descarga manual.

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ main.tf                 # Archivo principal de Terraform
‚îú‚îÄ‚îÄ variables.tf            # Definici√≥n de variables
‚îú‚îÄ‚îÄ outputs.tf              # Salidas del proyecto
‚îú‚îÄ‚îÄ terraform.tfvars        # Valores de las variables
‚îú‚îÄ‚îÄ modules/                # M√≥dulos de Terraform
‚îÇ   ‚îú‚îÄ‚îÄ storage/            # M√≥dulo para S3 buckets
‚îÇ   ‚îú‚îÄ‚îÄ processing/         # M√≥dulo para Glue, Lambda, Kinesis
‚îÇ   ‚îú‚îÄ‚îÄ analytics/          # M√≥dulo para Redshift, Athena
‚îÇ   ‚îú‚îÄ‚îÄ security/           # M√≥dulo para IAM roles y pol√≠ticas
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/         # M√≥dulo para CloudWatch y SNS
‚îÇ   ‚îî‚îÄ‚îÄ data_ingestion/     # M√≥dulo para descarga de datos de Kaggle
‚îú‚îÄ‚îÄ scripts/                # Scripts para Glue y Lambda
‚îÇ   ‚îú‚îÄ‚îÄ glue/               # Scripts de ETL para Glue
‚îÇ   ‚îú‚îÄ‚îÄ lambda/             # Funciones Lambda
‚îÇ   ‚îú‚îÄ‚îÄ create_kaggle_layer.sh  # Script para crear capa Lambda
‚îÇ   ‚îî‚îÄ‚îÄ trigger_kaggle_download.sh  # Script para ejecutar descarga manual
‚îî‚îÄ‚îÄ docs/                   # Documentaci√≥n adicional
    ‚îî‚îÄ‚îÄ architecture.png    # Diagrama de arquitectura
```

## üîß Requisitos Previos

- [Terraform](https://www.terraform.io/downloads.html) v1.2.0 o superior
- [AWS CLI](https://aws.amazon.com/cli/) configurado con credenciales adecuadas
- [Python](https://www.python.org/downloads/) 3.9 o superior (para scripts locales)
- [Cuenta de Kaggle](https://www.kaggle.com/) con API key para descarga autom√°tica
- [Git](https://git-scm.com/downloads) para clonar el repositorio

## üöÄ Gu√≠a de Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/Leonsang/fraud-detection-terraform.git
cd fraud-detection-terraform
```

### 2. Configurar Credenciales de AWS

```bash
export AWS_ACCESS_KEY_ID="tu_access_key"
export AWS_SECRET_ACCESS_KEY="tu_secret_key"
export AWS_DEFAULT_REGION="us-east-1"
```

En Windows PowerShell:

```powershell
$env:AWS_ACCESS_KEY_ID="tu_access_key"
$env:AWS_SECRET_ACCESS_KEY="tu_secret_key"
$env:AWS_DEFAULT_REGION="us-east-1"
```

### 3. Personalizar Variables

Revisa y modifica los valores en `terraform.tfvars` seg√∫n tus necesidades:

```hcl
# Configuraci√≥n general
aws_region   = "us-east-1"
project_name = "fraud-detection"
environment  = "dev"  # Cambia a "test" o "prod" seg√∫n sea necesario

# Configuraci√≥n de Kaggle
kaggle_username = "tu_usuario_kaggle"  # Reemplazar con tu usuario de Kaggle
kaggle_key      = "tu_api_key_kaggle"  # Reemplazar con tu API key de Kaggle
```

### 4. Configurar Credenciales de Kaggle

Para la descarga autom√°tica del dataset IEEE-CIS Fraud Detection:

1. Crea una cuenta en [Kaggle](https://www.kaggle.com/) si a√∫n no tienes una
2. Ve a tu perfil > Account > API > Create New API Token
3. Esto descargar√° un archivo `kaggle.json` con tus credenciales
4. Actualiza los valores en `terraform.tfvars` como se muestra arriba

### 5. Crear la Capa Lambda para Kaggle

```bash
# Dar permisos de ejecuci√≥n al script
chmod +x scripts/create_kaggle_layer.sh

# Ejecutar el script
./scripts/create_kaggle_layer.sh
```

### 6. Inicializar y Aplicar Terraform

```bash
# Inicializar Terraform
terraform init

# Crear un plan de ejecuci√≥n
terraform plan -out=tfplan

# Aplicar la configuraci√≥n
terraform apply tfplan
```

### 7. Ejecutar la Descarga de Datos Manualmente (opcional)

```bash
# Dar permisos de ejecuci√≥n al script
chmod +x scripts/trigger_kaggle_download.sh

# Ejecutar el script (reemplaza con el nombre real de la funci√≥n Lambda)
./scripts/trigger_kaggle_download.sh fraud-detection-dev-kaggle-downloader
```

### 8. Monitorear el Pipeline

Puedes monitorear el estado del pipeline a trav√©s de:

- **AWS Console**: CloudWatch Dashboard
- **CLI**: 
  ```bash
  # Ver estado del job de Glue
  aws glue get-job-runs --job-name fraud-detection-dev-etl-job
  
  # Ver logs de la funci√≥n Lambda
  aws logs get-log-events --log-group-name /aws/lambda/fraud-detection-dev-kaggle-downloader --log-stream-name $(aws logs describe-log-streams --log-group-name /aws/lambda/fraud-detection-dev-kaggle-downloader --query 'logStreams[0].logStreamName' --output text)
  ```

### 9. Destruir la Infraestructura (cuando ya no se necesite)

```bash
terraform destroy
```

## üß© Componentes Principales

### Almacenamiento (Storage) üíæ
- **Buckets S3**: Zonas Raw, Processed y Analytics
- **Caracter√≠sticas**: Cifrado en reposo, versionado, ciclo de vida
- **Particionamiento**: Por fecha para optimizar consultas

### Procesamiento (Processing) ‚öôÔ∏è
- **ETL**: Jobs de AWS Glue para transformaci√≥n de datos
- **Catalogaci√≥n**: Crawlers de Glue para metadatos
- **Tiempo Real**: Stream de Kinesis + Lambda
- **Validaci√≥n**: Funciones Lambda para calidad de datos
- **Estad√≠sticas**: Tabla DynamoDB para m√©tricas de tarjetas

### Anal√≠tica (Analytics) üìà
- **Data Warehouse**: Cluster de Redshift (solo en prod)
- **Consultas Ad-hoc**: Workgroup de Athena
- **Visualizaci√≥n**: Dashboards en QuickSight

### Seguridad (Security) üîí
- **IAM**: Roles con privilegios m√≠nimos
- **Cifrado**: KMS para datos sensibles
- **Acceso**: Pol√≠ticas granulares por servicio

### Monitoreo (Monitoring) üìä
- **M√©tricas**: Dashboard de CloudWatch
- **Alertas**: Alarmas para errores y anomal√≠as
- **Notificaciones**: Integraci√≥n con SNS para emails

## üìà Escalabilidad y Rendimiento

El sistema est√° dise√±ado para escalar seg√∫n las necesidades:

### Escenario: Incremento de datos en 100x
- S3 escala autom√°ticamente para almacenamiento
- Particionamiento optimizado para consultas eficientes
- Escalado de Glue con trabajadores adicionales
- Redshift con m√°s nodos para an√°lisis (en prod)

### Escenario: Ejecuci√≥n en ventanas de tiempo espec√≠ficas
- Programaci√≥n precisa con CloudWatch Events
- Monitoreo reforzado durante ventanas cr√≠ticas
- Reintentos autom√°ticos para garantizar completitud

### Escenario: Acceso por m√°s de 100 usuarios
- Redshift con escalado de concurrencia
- Athena para consultas distribuidas
- Capa de API con API Gateway para acceso program√°tico
- Pol√≠ticas de cach√© para consultas frecuentes

### Escenario: Anal√≠tica en tiempo real
- Procesamiento de streams con Kinesis
- Detecci√≥n de fraude en tiempo real con Lambda
- Alertas inmediatas v√≠a SNS
- Dashboards actualizados en tiempo real

## üìö Documentaci√≥n Detallada

Para m√°s informaci√≥n, consulta nuestra documentaci√≥n detallada:

### Gu√≠as de Configuraci√≥n
- [Gu√≠a de Instalaci√≥n y Ejecuci√≥n](docs/setup/SETUP_GUIDE.md)
- [Gu√≠a de Git](docs/setup/GIT_GUIDE.md)

### Documentaci√≥n T√©cnica
- [Detalles T√©cnicos del Sistema](docs/technical/TECHNICAL_DETAILS.md)
- [Estructura del Proyecto](docs/technical/PROJECT_STRUCTURE.md)

### Contexto del Proyecto
- [Contexto de la Prueba T√©cnica](docs/context/TECHNICAL_TEST_CONTEXT.md)
- [Cumplimiento de Requisitos](docs/context/TECHNICAL_TEST_COMPLIANCE.md)

### Diagramas
- [Arquitectura del Sistema](docs/diagrams/architecture.png)
- [Flujo de Datos](docs/diagrams/data_flow.png)

Para un √≠ndice completo de la documentaci√≥n, consulta el [√≠ndice de documentaci√≥n](docs/README.md).

## üìÑ Licencia

Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## üìû Contacto

Para preguntas o sugerencias, por favor abre un issue en este repositorio o contacta al equipo de desarrollo.

---

‚≠ê **¬øTe gusta este proyecto?** ¬°Dale una estrella en GitHub!
