{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis Detallado de Datos - Detección de Fraude\n",
        "\n",
        "Este notebook implementa un análisis profundo de los datos de transacciones para detección de fraude, utilizando servicios de AWS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración del Entorno AWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from datetime import datetime\n",
        "import json\n",
        "import logging\n",
        "\n",
        "# Configurar visualización\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Inicializar clientes AWS\n",
        "s3 = boto3.client('s3')\n",
        "athena = boto3.client('athena')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga y Preparación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar parámetros\n",
        "BUCKET = 'tu-bucket-s3'\n",
        "PREFIX = 'fraud-detection'\n",
        "DATABASE = 'fraud_detection_db'\n",
        "\n",
        "def load_data():\n",
        "    try:\n",
        "        # Consulta Athena para cargar datos\n",
        "        query = \"\"\"\n",
        "        SELECT *\n",
        "        FROM fraud_detection_db.transactions\n",
        "        \"\"\"\n",
        "        \n",
        "        # Ejecutar consulta\n",
        "        response = athena.start_query_execution(\n",
        "            QueryString=query,\n",
        "            QueryExecutionContext={'Database': DATABASE},\n",
        "            ResultConfiguration={\n",
        "                'OutputLocation': f's3://{BUCKET}/{PREFIX}/athena_results/'\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        # Esperar resultados\n",
        "        query_execution_id = response['QueryExecutionId']\n",
        "        while True:\n",
        "            status = athena.get_query_execution(QueryExecutionId=query_execution_id)['QueryExecution']['Status']['State']\n",
        "            if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
        "                break\n",
        "                \n",
        "        if status == 'SUCCEEDED':\n",
        "            # Cargar resultados en DataFrame\n",
        "            results = athena.get_query_results(QueryExecutionId=query_execution_id)\n",
        "            columns = [col['Name'] for col in results['ResultSet']['ResultSetMetadata']['ColumnInfo']]\n",
        "            data = []\n",
        "            for row in results['ResultSet']['Rows'][1:]:\n",
        "                data.append([field.get('VarCharValue', '') for field in row['Data']])\n",
        "            df = pd.DataFrame(data, columns=columns)\n",
        "            \n",
        "            logger.info(f\"Datos cargados exitosamente: {len(df)} registros\")\n",
        "            return df\n",
        "        else:\n",
        "            raise Exception(f\"Query failed with status: {status}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error al cargar datos: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "df = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análisis Temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_temporal_patterns(df):\n",
        "    try:\n",
        "        # Convertir tiempo a datetime\n",
        "        df['timestamp'] = pd.to_datetime(df['Time'], unit='s')\n",
        "        df['hour'] = df['timestamp'].dt.hour\n",
        "        df['day'] = df['timestamp'].dt.day\n",
        "        df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
        "        \n",
        "        # Análisis por hora\n",
        "        hourly_stats = df.groupby('hour').agg({\n",
        "            'Class': ['count', 'sum'],\n",
        "            'Amount': ['mean', 'std']\n",
        "        }).round(2)\n",
        "        \n        # Visualizar patrones por hora\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "        \n",
        "        # Tasa de fraude por hora\n",
        "        fraud_rate = df.groupby('hour')['Class'].mean()\n",
        "        fraud_rate.plot(kind='line', ax=ax1)\n",
        "        ax1.set_title('Tasa de Fraude por Hora')\n",
        "        \n",
        "        # Monto promedio por hora\n",
        "        amount_by_hour = df.groupby(['hour', 'Class'])['Amount'].mean().unstack()\n",
        "        amount_by_hour.plot(kind='bar', ax=ax2)\n",
        "        ax2.set_title('Monto Promedio por Hora y Clase')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/temporal_patterns.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráfico a S3\n",
        "        s3.upload_file(\n",
        "            '/tmp/temporal_patterns.png',\n",
        "            BUCKET,\n",
        "            f'{PREFIX}/analytics/plots/temporal_patterns.png'\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Análisis temporal completado\")\n",
        "        return hourly_stats.to_dict()\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis temporal: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "temporal_stats = analyze_temporal_patterns(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Análisis de Segmentación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_segments(df):\n",
        "    try:\n",
        "        # Crear segmentos por monto\n",
        "        df['amount_segment'] = pd.qcut(df['Amount'], q=5, labels=['Muy Bajo', 'Bajo', 'Medio', 'Alto', 'Muy Alto'])\n",
        "        \n        # Análisis por segmento\n",
        "        segment_stats = df.groupby('amount_segment').agg({\n",
        "            'Class': ['count', 'sum', 'mean'],\n",
        "            'Amount': ['min', 'max', 'mean', 'std']\n",
        "        }).round(2)\n",
        "        \n",
        "        # Visualizar estadísticas por segmento\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Tasa de fraude por segmento\n",
        "        fraud_by_segment = df.groupby('amount_segment')['Class'].mean()\n",
        "        fraud_by_segment.plot(kind='bar', ax=ax1)\n",
        "        ax1.set_title('Tasa de Fraude por Segmento')\n",
        "        \n",
        "        # Distribución de montos por segmento y clase\n",
        "        sns.boxplot(data=df, x='amount_segment', y='Amount', hue='Class', ax=ax2)\n",
        "        ax2.set_title('Distribución de Montos por Segmento y Clase')\n",
        "        plt.xticks(rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/segment_analysis.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráfico a S3\n",
        "        s3.upload_file(\n",
        "            '/tmp/segment_analysis.png',\n",
        "            BUCKET,\n",
        "            f'{PREFIX}/analytics/plots/segment_analysis.png'\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Análisis de segmentación completado\")\n",
        "        return segment_stats.to_dict()\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis de segmentación: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "segment_stats = analyze_segments(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análisis de Patrones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_patterns(df):\n",
        "    try:\n",
        "        # Análisis de secuencias\n",
        "        df['time_diff'] = df['Time'].diff()\n",
        "        df['amount_diff'] = df['Amount'].diff()\n",
        "        \n        # Estadísticas de secuencias\n",
        "        sequence_stats = {\n",
        "            'time_diffs': df.groupby('Class')['time_diff'].describe().to_dict(),\n",
        "            'amount_diffs': df.groupby('Class')['amount_diff'].describe().to_dict()\n",
        "        }\n",
        "        \n",
        "        # Visualizar patrones\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Distribución de diferencias de tiempo\n",
        "        sns.boxplot(data=df, x='Class', y='time_diff', ax=ax1)\n",
        "        ax1.set_title('Distribución de Intervalos de Tiempo por Clase')\n",
        "        \n",
        "        # Distribución de diferencias de monto\n",
        "        sns.boxplot(data=df, x='Class', y='amount_diff', ax=ax2)\n",
        "        ax2.set_title('Distribución de Diferencias de Monto por Clase')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/pattern_analysis.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráfico a S3\n",
        "        s3.upload_file(\n",
        "            '/tmp/pattern_analysis.png',\n",
        "            BUCKET,\n",
        "            f'{PREFIX}/analytics/plots/pattern_analysis.png'\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Análisis de patrones completado\")\n",
        "        return sequence_stats\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis de patrones: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "pattern_stats = analyze_patterns(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Análisis Estadístico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def statistical_analysis(df):\n",
        "    try:\n",
        "        # Pruebas estadísticas\n",
        "        statistical_tests = {}\n",
        "        \n        # T-test para montos entre clases\n",
        "        t_stat, p_value = stats.ttest_ind(\n",
        "            df[df['Class'] == 0]['Amount'],\n",
        "            df[df['Class'] == 1]['Amount']\n",
        "        )\n",
        "        statistical_tests['amount_ttest'] = {\n",
        "            't_statistic': float(t_stat),\n",
        "            'p_value': float(p_value)\n",
        "        }\n",
        "        \n",
        "        # Chi-square test para distribución temporal\n",
        "        contingency = pd.crosstab(df['hour'], df['Class'])\n",
        "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
        "        statistical_tests['temporal_chi2'] = {\n",
        "            'chi2_statistic': float(chi2),\n",
        "            'p_value': float(p_value),\n",
        "            'degrees_of_freedom': int(dof)\n",
        "        }\n",
        "        \n",
        "        # Visualizar distribuciones\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # QQ-plot de montos\n",
        "        stats.probplot(df['Amount'], dist=\"norm\", plot=ax1)\n",
        "        ax1.set_title('Q-Q Plot de Montos')\n",
        "        \n",
        "        # Distribución de probabilidad\n",
        "        sns.kdeplot(data=df, x='Amount', hue='Class', ax=ax2)\n",
        "        ax2.set_title('Densidad de Probabilidad de Montos por Clase')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/statistical_analysis.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráfico a S3\n",
        "        s3.upload_file(\n",
        "            '/tmp/statistical_analysis.png',\n",
        "            BUCKET,\n",
        "            f'{PREFIX}/analytics/plots/statistical_analysis.png'\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Análisis estadístico completado\")\n",
        "        return statistical_tests\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis estadístico: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "statistical_tests = statistical_analysis(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generación de Reporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_report(temporal_stats, segment_stats, pattern_stats, statistical_tests):\n",
        "    try:\n",
        "        # Crear reporte completo\n",
        "        report = {\n",
        "            'analysis_date': datetime.now().isoformat(),\n",
        "            'temporal_analysis': temporal_stats,\n",
        "            'segmentation_analysis': segment_stats,\n",
        "            'pattern_analysis': pattern_stats,\n",
        "            'statistical_analysis': statistical_tests,\n",
        "            'plots': {\n",
        "                'temporal': f'{PREFIX}/analytics/plots/temporal_patterns.png',\n",
        "                'segmentation': f'{PREFIX}/analytics/plots/segment_analysis.png',\n",
        "                'patterns': f'{PREFIX}/analytics/plots/pattern_analysis.png',\n",
        "                'statistical': f'{PREFIX}/analytics/plots/statistical_analysis.png'\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Guardar reporte en S3\n",
        "        s3.put_object(\n",
        "            Bucket=BUCKET,\n",
        "            Key=f'{PREFIX}/analytics/analysis_report.json',\n",
        "            Body=json.dumps(report, indent=2)\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Reporte de análisis generado exitosamente\")\n",
        "        return report\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error al generar reporte: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "analysis_report = generate_report(temporal_stats, segment_stats, pattern_stats, statistical_tests)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
} 