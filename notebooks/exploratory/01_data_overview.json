{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis Exploratorio de Datos - Detección de Fraude\n",
        "\n",
        "Este notebook implementa el análisis exploratorio inicial de los datos de transacciones para detección de fraude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración del Entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import logging\n",
        "\n",
        "# Configurar visualización\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Inicializar cliente S3\n",
        "s3 = boto3.client('s3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar parámetros\n",
        "BUCKET = 'tu-bucket-s3'\n",
        "PREFIX = 'fraud-detection'\n",
        "DATA_PATH = f's3://{BUCKET}/{PREFIX}/raw/creditcard.csv'\n",
        "\n",
        "def load_data():\n",
        "    try:\n",
        "        # Cargar datos desde S3\n",
        "        response = s3.get_object(Bucket=BUCKET, Key=f'{PREFIX}/raw/creditcard.csv')\n",
        "        df = pd.read_csv(response['Body'])\n",
        "        \n",
        "        logger.info(f\"Datos cargados exitosamente: {len(df)} registros\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error al cargar datos: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "df = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análisis Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initial_analysis(df):\n",
        "    try:\n",
        "        # Información básica\n",
        "        print(\"\\nInformación del Dataset:\")\n",
        "        print(df.info())\n",
        "        \n",
        "        # Estadísticas descriptivas\n",
        "        print(\"\\nEstadísticas Descriptivas:\")\n",
        "        print(df.describe())\n",
        "        \n",
        "        # Valores nulos\n",
        "        null_counts = df.isnull().sum()\n",
        "        print(\"\\nValores Nulos por Columna:\")\n",
        "        print(null_counts[null_counts > 0])\n",
        "        \n",
        "        # Distribución de clases\n",
        "        class_dist = df['Class'].value_counts(normalize=True)\n",
        "        print(\"\\nDistribución de Clases:\")\n",
        "        print(class_dist)\n",
        "        \n",
        "        return {\n",
        "            'shape': df.shape,\n",
        "            'null_counts': null_counts.to_dict(),\n",
        "            'class_distribution': class_dist.to_dict()\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis inicial: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "initial_stats = initial_analysis(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Análisis de Distribuciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_distributions(df):\n",
        "    try:\n",
        "        # Distribución de montos\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.histplot(data=df, x='Amount', hue='Class', bins=50)\n",
        "        plt.title('Distribución de Montos por Clase')\n",
        "        plt.savefig('/tmp/amount_distribution.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Distribución temporal\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.histplot(data=df, x='Time', hue='Class', bins=50)\n",
        "        plt.title('Distribución Temporal por Clase')\n",
        "        plt.savefig('/tmp/time_distribution.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Distribución de características V1-V28\n",
        "        v_cols = [f'V{i}' for i in range(1, 29)]\n",
        "        fig, axes = plt.subplots(7, 4, figsize=(20, 30))\n",
        "        for i, col in enumerate(v_cols):\n",
        "            row = i // 4\n",
        "            col_idx = i % 4\n",
        "            sns.boxplot(data=df, x='Class', y=col, ax=axes[row, col_idx])\n",
        "            axes[row, col_idx].set_title(f'Distribución de {col}')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/features_distribution.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráficos a S3\n",
        "        for plot in ['amount_distribution.png', 'time_distribution.png', 'features_distribution.png']:\n",
        "            s3.upload_file(\n",
        "                f'/tmp/{plot}',\n",
        "                BUCKET,\n",
        "                f'{PREFIX}/exploratory/plots/{plot}'\n",
        "            )\n",
        "            \n",
        "        logger.info(\"Análisis de distribuciones completado\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis de distribuciones: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "analyze_distributions(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análisis de Correlaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_correlations(df):\n",
        "    try:\n",
        "        # Matriz de correlación\n",
        "        corr_matrix = df.corr()\n",
        "        \n        # Visualizar correlaciones\n",
        "        plt.figure(figsize=(20, 16))\n",
        "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "        plt.title('Matriz de Correlación')\n",
        "        plt.savefig('/tmp/correlation_matrix.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Correlaciones con la variable objetivo\n",
        "        target_corr = corr_matrix['Class'].sort_values(ascending=False)\n",
        "        \n",
        "        # Visualizar correlaciones con objetivo\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        target_corr[1:11].plot(kind='bar')\n",
        "        plt.title('Top 10 Correlaciones con Clase')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/target_correlations.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráficos a S3\n",
        "        for plot in ['correlation_matrix.png', 'target_correlations.png']:\n",
        "            s3.upload_file(\n",
        "                f'/tmp/{plot}',\n",
        "                BUCKET,\n",
        "                f'{PREFIX}/exploratory/plots/{plot}'\n",
        "            )\n",
        "            \n",
        "        logger.info(\"Análisis de correlaciones completado\")\n",
        "        return target_corr.to_dict()\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis de correlaciones: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "correlations = analyze_correlations(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Análisis de Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_outliers(df):\n",
        "    try:\n",
        "        # Calcular estadísticas de outliers\n",
        "        outlier_stats = {}\n",
        "        for col in df.select_dtypes(include=[np.number]).columns:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]\n",
        "            outlier_stats[col] = {\n",
        "                'total_outliers': len(outliers),\n",
        "                'percent_outliers': len(outliers) / len(df) * 100,\n",
        "                'fraud_outliers': outliers['Class'].sum()\n",
        "            }\n",
        "        \n",
        "        # Visualizar outliers para características principales\n",
        "        main_features = ['Amount'] + [f'V{i}' for i in range(1, 5)]\n",
        "        fig, axes = plt.subplots(len(main_features), 1, figsize=(12, 4*len(main_features)))\n",
        "        \n",
        "        for i, feature in enumerate(main_features):\n",
        "            sns.boxplot(data=df, x='Class', y=feature, ax=axes[i])\n",
        "            axes[i].set_title(f'Outliers en {feature} por Clase')\n",
        "            \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('/tmp/outliers.png')\n",
        "        plt.close()\n",
        "        \n",
        "        # Subir gráfico a S3\n",
        "        s3.upload_file(\n",
        "            '/tmp/outliers.png',\n",
        "            BUCKET,\n",
        "            f'{PREFIX}/exploratory/plots/outliers.png'\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Análisis de outliers completado\")\n",
        "        return outlier_stats\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en análisis de outliers: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "outlier_stats = analyze_outliers(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generación de Reporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_report(initial_stats, correlations, outlier_stats):\n",
        "    try:\n",
        "        # Crear reporte completo\n",
        "        report = {\n",
        "            'analysis_date': datetime.now().isoformat(),\n",
        "            'dataset_info': initial_stats,\n",
        "            'correlations': correlations,\n",
        "            'outlier_analysis': outlier_stats,\n",
        "            'plots': {\n",
        "                'distributions': [\n",
        "                    f'{PREFIX}/exploratory/plots/amount_distribution.png',\n",
        "                    f'{PREFIX}/exploratory/plots/time_distribution.png',\n",
        "                    f'{PREFIX}/exploratory/plots/features_distribution.png'\n",
        "                ],\n",
        "                'correlations': [\n",
        "                    f'{PREFIX}/exploratory/plots/correlation_matrix.png',\n",
        "                    f'{PREFIX}/exploratory/plots/target_correlations.png'\n",
        "                ],\n",
        "                'outliers': f'{PREFIX}/exploratory/plots/outliers.png'\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Guardar reporte en S3\n",
        "        s3.put_object(\n",
        "            Bucket=BUCKET,\n",
        "            Key=f'{PREFIX}/exploratory/eda_report.json',\n",
        "            Body=json.dumps(report, indent=2)\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Reporte de análisis exploratorio generado exitosamente\")\n",
        "        return report\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error al generar reporte: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "eda_report = generate_report(initial_stats, correlations, outlier_stats)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
} 