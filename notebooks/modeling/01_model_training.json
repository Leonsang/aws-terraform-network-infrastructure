{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento de Modelos en AWS - Detección de Fraude\n",
        "\n",
        "Este notebook implementa el entrenamiento de modelos utilizando SageMaker y las mejores prácticas de AWS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuración del Entorno AWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3\n",
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "from sagemaker.xgboost import XGBoost\n",
        "from sagemaker.sklearn import SKLearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Inicializar sesión de SageMaker\n",
        "role = get_execution_role()\n",
        "session = sagemaker.Session()\n",
        "bucket = session.default_bucket()\n",
        "region = session.boto_region_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuración de Parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar parámetros\n",
        "PREFIX = 'fraud-detection'\n",
        "MODEL_DIR = f's3://{bucket}/{PREFIX}/models'\n",
        "TRAINING_DIR = f's3://{bucket}/{PREFIX}/training'\n",
        "OUTPUT_DIR = f's3://{bucket}/{PREFIX}/output'\n",
        "\n",
        "# Parámetros de entrenamiento\n",
        "TRAIN_INSTANCE = 'ml.m5.xlarge'\n",
        "DEPLOY_INSTANCE = 'ml.t2.medium'\n",
        "MODEL_VERSION = datetime.now().strftime('%Y%m%d_%H%M%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preparación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_training_data():\n",
        "    try:\n",
        "        # Cargar datos procesados de S3\n",
        "        s3_client = boto3.client('s3')\n",
        "        response = s3_client.get_object(Bucket=bucket, Key=f'{PREFIX}/processed/processed_features.parquet')\n",
        "        df = pd.read_parquet(response['Body'])\n",
        "        \n",
        "        # Separar características y target\n",
        "        X = df.drop('Class', axis=1)\n",
        "        y = df['Class']\n",
        "        \n",
        "        # Dividir datos\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        \n",
        "        # Guardar datos en formato SageMaker\n",
        "        train_data = pd.concat([y_train, X_train], axis=1)\n",
        "        test_data = pd.concat([y_test, X_test], axis=1)\n",
        "        \n",
        "        train_path = f'{TRAINING_DIR}/train.csv'\n",
        "        test_path = f'{TRAINING_DIR}/test.csv'\n",
        "        \n",
        "        train_data.to_csv(train_path, index=False, header=False)\n",
        "        test_data.to_csv(test_path, index=False, header=False)\n",
        "        \n",
        "        logger.info(\"Datos preparados exitosamente\")\n",
        "        return train_path, test_path\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en preparación de datos: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "train_path, test_path = prepare_training_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Configuración de Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def configure_xgboost():\n",
        "    try:\n",
        "        # Configurar hiperparámetros\n",
        "        hyperparameters = {\n",
        "            'max_depth': 7,\n",
        "            'eta': 0.1,\n",
        "            'gamma': 4,\n",
        "            'min_child_weight': 6,\n",
        "            'subsample': 0.8,\n",
        "            'objective': 'binary:logistic',\n",
        "            'num_round': 100,\n",
        "            'eval_metric': ['auc', 'error']\n",
        "        }\n",
        "        \n",
        "        # Crear estimador XGBoost\n",
        "        xgb = XGBoost(\n",
        "            entry_point='train.py',\n",
        "            framework_version='1.5-1',\n",
        "            hyperparameters=hyperparameters,\n",
        "            role=role,\n",
        "            instance_count=1,\n",
        "            instance_type=TRAIN_INSTANCE,\n",
        "            output_path=MODEL_DIR\n",
        "        )\n",
        "        \n",
        "        return xgb\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en configuración de XGBoost: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "xgb_model = configure_xgboost()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Entrenamiento de Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_path, test_path):\n",
        "    try:\n",
        "        # Entrenar modelo\n",
        "        model.fit({\n",
        "            'train': train_path,\n",
        "            'validation': test_path\n",
        "        })\n",
        "        \n        # Registrar métricas de entrenamiento\n",
        "        training_job = model.latest_training_job\n",
        "        metrics = training_job.describe()['TrainingMetrics']\n",
        "        \n",
        "        logger.info(f\"Métricas de entrenamiento: {metrics}\")\n",
        "        return model, metrics\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en entrenamiento: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "trained_model, training_metrics = train_model(xgb_model, train_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Despliegue del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deploy_model(model):\n",
        "    try:\n",
        "        # Desplegar modelo\n",
        "        predictor = model.deploy(\n",
        "            initial_instance_count=1,\n",
        "            instance_type=DEPLOY_INSTANCE,\n",
        "            endpoint_name=f'fraud-detection-{MODEL_VERSION}'\n",
        "        )\n",
        "        \n",
        "        # Registrar endpoint\n",
        "        endpoint_info = {\n",
        "            'endpoint_name': predictor.endpoint_name,\n",
        "            'model_version': MODEL_VERSION,\n",
        "            'deployment_date': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        s3_client = boto3.client('s3')\n",
        "        s3_client.put_object(\n",
        "            Bucket=bucket,\n",
        "            Key=f'{PREFIX}/endpoints/endpoint_info.json',\n",
        "            Body=json.dumps(endpoint_info)\n",
        "        )\n",
        "        \n",
        "        logger.info(f\"Modelo desplegado en endpoint: {predictor.endpoint_name}\")\n",
        "        return predictor\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en despliegue: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "predictor = deploy_model(trained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluación del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(predictor, test_path):\n",
        "    try:\n",
        "        # Cargar datos de prueba\n",
        "        test_data = pd.read_csv(test_path)\n",
        "        X_test = test_data.drop('Class', axis=1)\n",
        "        y_test = test_data['Class']\n",
        "        \n",
        "        # Realizar predicciones\n",
        "        predictions = predictor.predict(X_test.values)\n",
        "        \n",
        "        # Calcular métricas\n",
        "        from sklearn.metrics import classification_report, confusion_matrix\n",
        "        report = classification_report(y_test, predictions)\n",
        "        cm = confusion_matrix(y_test, predictions)\n",
        "        \n",
        "        # Guardar resultados\n",
        "        evaluation_results = {\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm.tolist(),\n",
        "            'evaluation_date': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        s3_client = boto3.client('s3')\n",
        "        s3_client.put_object(\n",
        "            Bucket=bucket,\n",
        "            Key=f'{PREFIX}/evaluation/results_{MODEL_VERSION}.json',\n",
        "            Body=json.dumps(evaluation_results)\n",
        "        )\n",
        "        \n",
        "        logger.info(\"Evaluación completada exitosamente\")\n",
        "        return evaluation_results\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en evaluación: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "evaluation_results = evaluate_model(predictor, test_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
} 